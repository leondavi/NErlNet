{
  "NerlNetSettings": [
  {
    "frequency": "10",
    "batchSize": "10"
  }
  ],
  "devices": [
    {
      "host": "127.0.0.1",
      "entities": "mainServer,c1,f1,s1,r1"
    }
  ],
  "serverAPI": [
    {
      "host": "127.0.0.1",
      "port": "8095",
      "args": ""
    }
  ],
  "mainServer": [
    {
      "host": "127.0.0.1",
      "port": "8080",
      "args": ""
    }
  ],
  "workers": [
    {
      "name": "w1",
      "modelId": "0",
      "modelType": "2",
      "_comment0": "Model Type Explenation: TODO",
      "scalingMethod": "1",
      "_comment1": "Scaling Method Explenation: TODO",
      "layerTypesList": "[1,1,1,3]",
      "layersSizes": "[6,1,1,128,64,32,16,4,1]",
      "_comment2": "Activation functions explain: 0- NONE, 1- IDENTITY, 2- SIGMOID, 3- RELU, 4- LEAKY_RELU, 5- SWISH, 6- ELU, 7- TANH, 8- GAUSSIAN, 9- TOTAL",
      "layersActivationFunctions":"[5,1,1,0,0,0,0,0]",
      "federatedMode": "0",
      "countLimit": "10",
      "_comment3": "OptimizerExplain: 0- NONE, 1- SGD, 2- MINI_BATCH_SGD, 3- MOMENTUM, 4- NAG, 5- ADAGRAD, 6- ADAM",
      "optimizer":"6",
      "features": "128",
      "labels": "1"
    }
  ],
  "clients": [
    {
      "name": "c1",
      "port": "8081",
      "workers": "w1",
      "federated": "f1"
    }
  ],
  "federated": [
    {
      "name": "f1",
      "port": "8083",
      "workers": "w1",
      "counterLimit": "1"
    }
  ],
  "sources": [
    {
      "name": "s1",
      "port": "8091",
      "method": "1",
      "COMMENTS": "method allowed: '1': sends each exapme to all clients listed, '2': round robin between all clients"
    }
  ],
 "routers": [
    {
      "name": "r1",
      "host": "127.0.0.1",
      "port": "8084"
    }
  ]
}
