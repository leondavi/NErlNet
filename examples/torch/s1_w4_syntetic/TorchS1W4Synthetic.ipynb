{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7364ad50",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Nerlnet 1.6.0 is built (`./NerlnetBuild.sh --infra torch`).\n",
    "- Synthetic CSV is synced to `/tmp/nerlnet/data/NerlnetData-master/nerlnet/synthetic_norm/synthetic_full.csv`.\n",
    "- The example JSONs (`exp_torch_s1_w4.json`, `dc_torch_s1_w4.json`, `conn_torch_s1_w4.json`) remain inside `examples/torch/s1_w4_syntetic`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a405b6",
   "metadata": {},
   "source": [
    "## 1. Generate the TorchScript model\n",
    "The following cell recreates the placeholder perceptron that matches the JSON metadata and writes it to `examples/torch/s1_w4_syntetic/models/synthetic_torch_example.pt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e47c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "output_path = Path(\"examples/torch/s1_w4_syntetic/models/synthetic_torch_example.pt\").resolve()\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    \"tests/scripts/generate_torch_test_model.py\",\n",
    "    \"--output\", str(output_path),\n",
    "    \"--samples\", \"2000\",\n",
    "    \"--epochs\", \"400\",\n",
    "    \"--lr\", \"0.005\"\n",
    "]\n",
    "print(\"Creating TorchScript model at\", output_path)\n",
    "subprocess.run(cmd, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8371ba35",
   "metadata": {},
   "source": [
    "## 2. Inspect the distributed configuration\n",
    "This helper cell visualizes the Torch worker definition and confirms the per-batch metadata that the worker expects during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d2fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open(\"examples/torch/s1_w4_syntetic/dc_torch_s1_w4.json\", \"r\", encoding=\"utf-8\") as handle:\n",
    "    dc = json.load(handle)\n",
    "workers = dc[\"workers\"]\n",
    "train_params = dc[\"model_sha\"][\"torch_s1w4_v160\"][\"train_params\"]\n",
    "print(\"Workers bound to the example model:\")\n",
    "pprint(workers)\n",
    "print(\"\n",
    "Torch training parameters:\")\n",
    "pprint(train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b2a31",
   "metadata": {},
   "source": [
    "## 3. Stage the JSONs and launch Nerlnet\n",
    "1. Copy or symlink the JSON files into the paths referenced by `config/jsonsDir.nerlconfig` and `config/subnets.nerlconfig` (for example, point `dc.json` to `examples/torch/s1_w4_syntetic/dc_torch_s1_w4.json`).\n",
    "2. Ensure `conn.json` resolves to `examples/torch/s1_w4_syntetic/conn_torch_s1_w4.json` and the experiment description is reachable at `examples/torch/s1_w4_syntetic/exp_torch_s1_w4.json`.\n",
    "3. Build or rebuild the native bridges if anything changed (`./NerlnetBuild.sh --infra all`).\n",
    "4. Launch the Erlang application via `./NerlnetRun.sh` in one terminal and keep it running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35faaa58",
   "metadata": {},
   "source": [
    "## 4. Kick off the Torch full-flow\n",
    "With Nerlnet running, trigger the example from a second terminal:\n",
    "```bash\n",
    "tests/NerlnetFullFlowTorchTest.sh --manual-start \\\n",
    "  --experiment examples/torch/s1_w4_syntetic/exp_torch_s1_w4.json \\\n",
    "  --dc examples/torch/s1_w4_syntetic/dc_torch_s1_w4.json \\\n",
    "  --conn examples/torch/s1_w4_syntetic/conn_torch_s1_w4.json\n",
    "```\n",
    "As batches stream through `s1`, each worker (`w1`-`w4`) stays active on the Torch bridge, preserving optimizer momentum and weights between messages.\n",
    "Once both training and prediction phases finish, inspect `/tmp/nerlnet/results/` for anomaly summaries and `/tmp/nerlnet/torch/models/pt/` for updated checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5130be6",
   "metadata": {},
   "source": [
    "## 5. Analyze outcomes\n",
    "Review `test_torch.log` (or the CSVs saved under `/tmp/nerlnet/results/.../model_perf.csv`) to compare Torch metrics against the OpenNN baseline. If the anomaly scores diverge, double-check that the generated TorchScript file matches the shapes advertised in `train_params` and that the JSON paths inside `config/jsonsDir.nerlconfig` are up to date."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
