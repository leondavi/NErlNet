{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5857ec6-9bcc-4761-a609-1d4b4f51417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_jupyter_env\n",
    "from apiServer import *\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1bc927-b010-437b-811a-a9f6cc617e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "__________NERLNET CHECKLIST__________\n",
      "Nerlnet configuration files are located at config directory.\n",
      "Make sure data and jsons in correct folder, and jsons include the correct paths\n",
      "* Data includes: a single csv that includes all the data for the experiment (training and prediction phases)\n",
      "* Jsons include: - distributed configuration (dc_<name>.json)\n",
      "                 - connection map (conn_<name>.json)\n",
      "                 - experiment flow (exp_<name>.json)\n",
      "* Jsons directory: can be defined by changing the config file: config/jsonsDir.nerlconfig\n",
      "\n",
      "____________API COMMANDS_____________\n",
      "==========Setting experiment========\n",
      "\n",
      "-showJsons():                                           lists available json files in jsons directory (dc, conn, exp) to be used with setJsons and getUserJsons\n",
      "-list_datasets():                                       reads `hf_repo_ids.json` and list of datasets and files of Nerlnet organizaion on https://huggingface.co/Nerlnet\n",
      "-download_dataset(idx, dir):                            downloads dataset files from Huggingface to the specified directory (default is /tmp/nerlnet/data/NerlnetData-master/nerlnet)\n",
      "-add_repo_to_datasets_list(repo, name , description):   adds a repository to the datasets list in `hf_repo_ids.json`\n",
      "-printArchParams(Num)                                   print description of selected arch file\n",
      "\n",
      "-selectJsons():                                         get input from user for arch / conn / exp selection\n",
      "-setJsons(arch, conn, exp):                             set selected jsons to get their path by getUserJsons\n",
      "-getUserJsons():                                        return a tuple of 3 paths to dc, conn, exp jsons that is used for initialization\n",
      "\n",
      "-initialization(experiment_name, dc, conn, exp_flow, custom_csv_path):  \n",
      "                                                        setting up the api-server to communicate with main-server of Nerlnet cluster\n",
      "                                                        dc - path to distributed configuration file (can be generated by Nerlplanner)\n",
      "                                                        conn - path to connection map file, graph of connections between entities\n",
      "                                                        exp - path to experiment flow file, defines the flow of the experiment demonstrated as experiment phases of training and prediction\n",
      "                                                        custom_csv_path - optional, path to custom csv file for the experiment, overrides the one in experiment flow file\n",
      "                                                        \n",
      "-send_jsons_to_devices():                               send each NerlNet device the dc and conn jsons to init entities on it\n",
      "-sendDataToSources(phase(,split)):                      phase := \"training\" | \"prediction\". split := 1 default (split) | 2 (whole file). send the experiment data to sources (currently happens in beggining of train/predict)\n",
      "\n",
      "======== Running experiment ==========\n",
      "-experiment_phase_is_valid()        returns True if there are more experiment phases to run\n",
      "-run_current_experiment_phase()     runs the current experiment phase\n",
      "-next_experiment_phase()            moves to the next experiment phase\n",
      "\n",
      "======== Retrieving statistics ======\n",
      "-get_experiment_flow(experiment_name).generate_stats()   returns statistics object (E.g., assigned to StatsInst) class for the current experiment phase\n",
      "-StatsInst.get_communication_stats_workers()         returns communication statistics for workers\n",
      "-StatsInst.get_communication_stats_sources()         returns communication statistics for sources\n",
      "-StatsInst.get_communication_stats_clients()         returns communication statistics for clients\n",
      "-StatsInst.get_communication_stats_routers()         returns communication statistics for routers\n",
      "-StatsInst.get_communication_stats_main_server()     returns communication statistics for main server\n",
      "-StatsInst.get_loss_ts()                             returns the loss over time\n",
      "-StatsInst.get_min_loss()                            returns the minimum loss\n",
      "-StatsInst.get_missed_batches()                      returns the missed batches\n",
      "\n",
      "======== Workers Model Metrics and Performance ========\n",
      "-StatsInst.get_confusion_matrices()                  returns tuple of two types of confusion matrices ordered by sources and ordered by workers\n",
      "-StatsInst.get_model_performence_stats(confusion_matrix_worker_dict, saveToFile) returns the model performance statistics for the workers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "API = ApiServer()\n",
    "API.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85711cb8-3e14-4659-bbd1-c0b6bb7f7ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distributed Configuration Files\n",
      "--------------------\n",
      "\n",
      "0.\tdc_10w_14d_8r_3s_10c_synt.json\n",
      "1.\tdc_AEC_1d_2c_1s_4r_4w.json\n",
      "2.\tdc_EEG_1d_1c_3s_2r_1w.json\n",
      "3.\tdc_dist_14d.json\n",
      "4.\tdc_dist_2d_3c_2s_3r_6w.json\n",
      "5.\tdc_fed_dist_14d.json\n",
      "6.\tdc_fed_dist_2d_3c_2s_3r_6w.json\n",
      "7.\tdc_fed_synt_1d_2c_2r_1s_4w_1ws.json\n",
      "8.\tdc_synt_8d_8w_2c_4s_4r.json\n",
      "9.\tdc_synt_8d_8w_4c_6r_4s.json\n",
      "10.\tdc_synt_distributed_w5_c3_6r_3s_3d.json\n",
      "11.\tdc_test_synt_1d_2c_1s_4r_4w.json\n",
      "12.\tdc_test_synt_1d_2c_2s_4r_4w.json\n",
      "\n",
      "Connection Map Files\n",
      "--------------------\n",
      "\n",
      "0.\tconn_1Router1Client1S.json\n",
      "1.\tconn_1Router1Client2S.json\n",
      "2.\tconn_1Router2Clients1S.json\n",
      "3.\tconn_1Router3Clients1S.json\n",
      "4.\tconn_1Router4Clients1S.json\n",
      "5.\tconn_1Router4Clients1fed.json\n",
      "6.\tconn_1Router4Clients2Sources.json\n",
      "7.\tconn_1Router4Clients2Sources1fed.json\n",
      "8.\tconn_2R4C1S_health_david.json\n",
      "9.\tconn_2Router2Clients1Source.json\n",
      "10.\tconn_2Router2Clients1Source_david.json\n",
      "11.\tconn_2Router2Clients2Source.json\n",
      "12.\tconn_2Router2ClientsGUI.json\n",
      "13.\tconn_2Router3Clients.json\n",
      "14.\tconn_3Router3Clients.json\n",
      "15.\tconn_6RouterCycle6Clients1Source.json\n",
      "16.\tconn_6RouterCycle8Clients1Source.json\n",
      "17.\tconn_6RouterLine6Clients1Source.json\n",
      "18.\tconn_8RouterCycle8Clients1Source.json\n",
      "19.\tconn_8Routers10Clients3S.json\n",
      "20.\tconn_EEG_2Router1Clients3Source_EEG.json\n",
      "21.\tconn_fed_dist_14d.json\n",
      "22.\tconn_fed_dist_2d_3c_2s_3r_6w.json\n",
      "23.\tconn_fed_synt_1d_2c_2r_1s_4w_1ws.json\n",
      "24.\tconn_synt_8d_8w_4c_6r_4s.json\n",
      "25.\tconn_synt_dc_8d_8w_2c_4s_4r.json\n",
      "26.\tconn_synt_distributed_w5_c3_6r_3s_3d.json\n",
      "27.\tconn_test_synt_1d_2c_1s_4r_4w.json\n",
      "28.\tconn_test_synt_1d_2c_2s_4r_4w.json\n",
      "\n",
      "Experiments Flow Files\n",
      "--------------------\n",
      "\n",
      "0.\texp_AEC_1d_2c_1s_4r_4w.json\n",
      "1.\texp_EEG_1d_1c_3s_2r_1w.json\n",
      "2.\texp_dist_14d.json\n",
      "3.\texp_dist_14d_10c_3s_8r_10w.json\n",
      "4.\texp_dist_2d_3c_2s_3r_6w.json\n",
      "5.\texp_fed_dist_14d.json\n",
      "6.\texp_fed_dist_2d_3c_2s_3r_6w.json\n",
      "7.\texp_fed_synt_1d_2c_2r_1s_4w_1ws.json\n",
      "8.\texp_new_arc.json\n",
      "9.\texp_synt_8d_8w_2c_4s_4r.json\n",
      "10.\texp_synt_8d_8w_4c_6r_4s.json\n",
      "11.\texp_synt_distributed_w5_c3_6r_3s_3d.json\n",
      "12.\texp_test_synt_1d_2c_1s_4r_4w new.json\n"
     ]
    }
   ],
   "source": [
    "API.showJsons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27ebe0a-f861-4f1a-8dbb-f04914acd7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = 2\n",
    "conn = 20\n",
    "exp = 1\n",
    "API.setJsons(dc , conn , exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f5fad3d-f319-4ad4-83b1-bea88b8701d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_path , conn_path , exp_path = API.getUserJsons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b22a24c9-1f75-439a-9830-16a45e528fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2024-07-15 14:39:42,741] \n",
      "Network components:\n",
      "                 Receiver's Address: http://10.0.0.8:8901\n",
      "                 Frequency: 200 [batches/sec]\n",
      "                 Batchsize: 5 [samples]\n",
      "                 devicesIp: ['10.0.0.8']\n",
      "                 mainServerIp: 10.0.0.8\n",
      "                 mainServerPort: 8900\n",
      "                 apiServerIp: 10.0.0.8\n",
      "                 apiServerPort: 8901\n",
      "                 Clients: ['c1', 'c2', 'c3']\n",
      "                 Workers: ['w1', 'w2', 'w3']\n",
      "                 Sources: ['s1', 's2', 's3']\n",
      "                 Routers: ['r1', 'r2']\n",
      "[INFO][2024-07-15 14:39:42,742] Connections:\n",
      "[INFO][2024-07-15 14:39:42,743] \t\t r1 : ['mainServer', 'c1', 'c2', 'c3', 'r2']\n",
      "[INFO][2024-07-15 14:39:42,743] \t\t r2 : ['s1', 's2', 's3', 'r1']\n",
      "[INFO][2024-07-15 14:39:42,744] Experiment name: EEG_Valence_Recognition_DEAP\n",
      "[INFO][2024-07-15 14:39:42,745] Batch size: 5\n",
      "[INFO][2024-07-15 14:39:42,745] Number of features: 70\n",
      "[INFO][2024-07-15 14:39:42,745] Number of labels: 9\n",
      "[INFO][2024-07-15 14:39:42,746] \n",
      "[INFO][2024-07-15 14:39:42,746] Phases:\n",
      "[INFO][2024-07-15 14:39:42,747]    Phase name: training_phase\n",
      "[INFO][2024-07-15 14:39:42,747]    Phase type: training\n",
      "[INFO][2024-07-15 14:39:42,749]    Sources: s1,s2,s3\n",
      "[INFO][2024-07-15 14:39:42,750] \n",
      "[INFO][2024-07-15 14:39:42,750]     Source pieces:\n",
      "[INFO][2024-07-15 14:39:42,751]          Source name: s1\n",
      "[INFO][2024-07-15 14:39:42,752]          Batch size: 5\n",
      "[INFO][2024-07-15 14:39:42,753]          Phase: training\n",
      "[INFO][2024-07-15 14:39:42,753]          Starting offset: 0\n",
      "[INFO][2024-07-15 14:39:42,754]          Number of batches: 800\n",
      "[INFO][2024-07-15 14:39:42,755]          Workers target: w1\n",
      "[INFO][2024-07-15 14:39:42,755]       ----------------------\n",
      "[INFO][2024-07-15 14:39:42,756] \n",
      "[INFO][2024-07-15 14:39:42,756]          Source name: s2\n",
      "[INFO][2024-07-15 14:39:42,757]          Batch size: 5\n",
      "[INFO][2024-07-15 14:39:42,757]          Phase: training\n",
      "[INFO][2024-07-15 14:39:42,758]          Starting offset: 19520\n",
      "[INFO][2024-07-15 14:39:42,760]          Number of batches: 800\n",
      "[INFO][2024-07-15 14:39:42,760]          Workers target: w2\n",
      "[INFO][2024-07-15 14:39:42,761]       ----------------------\n",
      "[INFO][2024-07-15 14:39:42,761] \n",
      "[INFO][2024-07-15 14:39:42,761]          Source name: s3\n",
      "[INFO][2024-07-15 14:39:42,762]          Batch size: 5\n",
      "[INFO][2024-07-15 14:39:42,762]          Phase: training\n",
      "[INFO][2024-07-15 14:39:42,763]          Starting offset: 39040\n",
      "[INFO][2024-07-15 14:39:42,763]          Number of batches: 800\n",
      "[INFO][2024-07-15 14:39:42,764]          Workers target: w3\n",
      "[INFO][2024-07-15 14:39:42,764]       ----------------------\n",
      "[INFO][2024-07-15 14:39:42,765] \n",
      "[INFO][2024-07-15 14:39:42,765]    Phase name: prediction_phase\n",
      "[INFO][2024-07-15 14:39:42,766]    Phase type: prediction\n",
      "[INFO][2024-07-15 14:39:42,766]    Sources: s1,s2,s3\n",
      "[INFO][2024-07-15 14:39:42,767] \n",
      "[INFO][2024-07-15 14:39:42,767]     Source pieces:\n",
      "[INFO][2024-07-15 14:39:42,768]          Source name: s1\n",
      "[INFO][2024-07-15 14:39:42,770]          Batch size: 5\n",
      "[INFO][2024-07-15 14:39:42,772]          Phase: prediction\n",
      "[INFO][2024-07-15 14:39:42,773]          Starting offset: 15610\n",
      "[INFO][2024-07-15 14:39:42,773]          Number of batches: 200\n",
      "[INFO][2024-07-15 14:39:42,774]          Workers target: w1\n",
      "[INFO][2024-07-15 14:39:42,775]       ----------------------\n",
      "[INFO][2024-07-15 14:39:42,775] \n",
      "[INFO][2024-07-15 14:39:42,776]          Source name: s2\n",
      "[INFO][2024-07-15 14:39:42,776]          Batch size: 5\n",
      "[INFO][2024-07-15 14:39:42,777]          Phase: prediction\n",
      "[INFO][2024-07-15 14:39:42,778]          Starting offset: 35130\n",
      "[INFO][2024-07-15 14:39:42,778]          Number of batches: 200\n",
      "[INFO][2024-07-15 14:39:42,779]          Workers target: w2\n",
      "[INFO][2024-07-15 14:39:42,779]       ----------------------\n",
      "[INFO][2024-07-15 14:39:42,780] \n",
      "[INFO][2024-07-15 14:39:42,781]          Source name: s3\n",
      "[INFO][2024-07-15 14:39:42,781]          Batch size: 5\n",
      "[INFO][2024-07-15 14:39:42,782]          Phase: prediction\n",
      "[INFO][2024-07-15 14:39:42,782]          Starting offset: 54650\n",
      "[INFO][2024-07-15 14:39:42,783]          Number of batches: 200\n",
      "[INFO][2024-07-15 14:39:42,784]          Workers target: w3\n",
      "[INFO][2024-07-15 14:39:42,784]       ----------------------\n",
      "[INFO][2024-07-15 14:39:42,785] \n",
      "[INFO][2024-07-15 14:39:42,786] Initializing ApiServer receiver thread\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'receiver'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2024-07-15 14:39:44,789] *** Remember to execute NerlnetRun.sh on each device before running the experiment! ***\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"EEG_Emotion_1Device_Persons\"\n",
    "API.initialization(exp_name, dc_path, conn_path, exp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "201b6d41-c968-40f8-a66a-bf83b9188173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2024-07-15 14:39:45,093] Sending distributed configurations to devices is completed\n"
     ]
    }
   ],
   "source": [
    "API.send_jsons_to_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d3604-28be-407b-9780-edfeb2d6d696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2024-07-15 14:39:45,099] Experiment phase: training_phase of type training starts running...\n",
      "[INFO][2024-07-15 14:39:45,102] Sending data to sources\n",
      "[INFO][2024-07-15 14:40:02,628] Data is ready in sources\n",
      "[INFO][2024-07-15 14:40:02,817] Phase training requested from Main Server\n"
     ]
    }
   ],
   "source": [
    "API.run_current_experiment_phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c6157-8589-4ebf-86e3-449a4e777c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_train = API.get_experiment_flow(exp_name).generate_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cae22-8123-4fe4-a1e3-9ef665e22440",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_train.get_loss_ts(plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
